{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58d44957",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Keyword arguments {'dtype': torch.float16} are not expected by StableDiffusionImg2ImgPipeline and will be ignored.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "975026f71baa47398b8df025246e4325",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.StableDiffusionImg2ImgPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be1149acd98c4d07bbea8db70eca96f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "from diffusers import StableDiffusionImg2ImgPipeline\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', message='.*safety checker.*')\n",
    "\n",
    "def Diffusion(img_path):\n",
    "    if not hasattr(Diffusion, 'pipe'):\n",
    "        pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "            'runwayml/stable-diffusion-v1-5',\n",
    "            dtype=torch.float16,\n",
    "            cache_dir='/opt/dlami/nvme/huggingface',\n",
    "            safety_checker=None\n",
    "        )\n",
    "        pipe.to('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "        pipe.enable_vae_tiling()\n",
    "        # pipe.enable_xformers_memory_efficient_attention(),\n",
    "        Diffusion.pipe = pipe\n",
    "\n",
    "    pipe = Diffusion.pipe\n",
    "    init_image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        generator = torch.Generator(device='cuda').manual_seed(torch.randint(0, 2 ** 32 - 1, (1,)).item())\n",
    "        generated = pipe(\n",
    "            prompt=\"An ancient glass bead excavated in Japan, smooth surface, realistic, subtle imperfections, natural color\",\n",
    "            negative_prompt=\"clustered particles, bumpy surface, multiple beads, noise, abstract\",\n",
    "            image=init_image,\n",
    "            strength=0.45,\n",
    "            guidance_scale=5.5,\n",
    "            num_inference_steps=25,\n",
    "            generator=generator\n",
    "        ).images[0]\n",
    "    generated.save('Data/1564_gen.jpg')\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "Diffusion('Data/Few_Sample/Top/mix-Al/1564.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9815f76b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 枚の画像を処理します。\n",
      "生成中: 4109.jpg...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c0c6e3ef746c45cb90c5620a74e48f46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.StableDiffusionImg2ImgPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff29d93f8b9f47edaae2e948a38ae818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import gc\n",
    "from diffusers import StableDiffusionImg2ImgPipeline\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"diffusers\")\n",
    "\n",
    "\n",
    "def Diffusion(img_path, save_path):\n",
    "\n",
    "    if not hasattr(Diffusion, 'pipe'):\n",
    "        pipe = StableDiffusionImg2ImgPipeline.from_pretrained(\n",
    "            'runwayml/stable-diffusion-v1-5',\n",
    "            torch_dtype=torch.float16,          # ← 正しい引数名\n",
    "            cache_dir='/opt/dlami/nvme/huggingface',\n",
    "            safety_checker=None\n",
    "        )\n",
    "\n",
    "        # テキストエンコーダは CPU に残す（メモリ節約 約2GB）\n",
    "        pipe.text_encoder.to(\"cpu\")\n",
    "\n",
    "        # UNet・VAE は GPU に\n",
    "        device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "        pipe.to(device)\n",
    "\n",
    "        # メモリ効率化\n",
    "        pipe.vae.enable_tiling()\n",
    "        pipe.enable_vae_tiling()\n",
    "        try:\n",
    "            pipe.enable_xformers_memory_efficient_attention()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "        Diffusion.pipe = pipe\n",
    "\n",
    "    pipe = Diffusion.pipe\n",
    "\n",
    "    init_image = Image.open(img_path).convert(\"RGB\")\n",
    "\n",
    "    with torch.inference_mode():\n",
    "        generator = torch.Generator(device='cuda' if torch.cuda.is_available() else 'cpu').manual_seed(\n",
    "            torch.randint(0, 2**32 - 1, (1,)).item()\n",
    "        )\n",
    "\n",
    "        generated = pipe(\n",
    "            prompt=\"An ancient glass bead excavated in Japan, smooth surface, realistic, subtle imperfections, natural color\",\n",
    "            negative_prompt=\"clustered particles, bumpy surface, multiple beads, noise, abstract\",\n",
    "            image=init_image,\n",
    "            strength=0.45,\n",
    "            guidance_scale=5.5,\n",
    "            num_inference_steps=15,\n",
    "            generator=generator\n",
    "        ).images[0]\n",
    "\n",
    "    generated.save(save_path)\n",
    "\n",
    "    # メモリ解放\n",
    "    del generator\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "\n",
    "# =======================================\n",
    "#  一括処理\n",
    "# =======================================\n",
    "\n",
    "name = 'LI'\n",
    "\n",
    "input_dir  = f\"Data/Few_Sample/Top/{name}/\"\n",
    "output_dir = f\"Data/Diffusion/Top/{name}/\"\n",
    "\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "valid_ext = (\".jpg\", \".png\", \".jpeg\", \".bmp\", \".webp\")\n",
    "files = [f for f in os.listdir(input_dir) if f.lower().endswith(valid_ext)]\n",
    "\n",
    "print(f\"{len(files)} 枚の画像を処理します。\")\n",
    "\n",
    "for fname in files:\n",
    "    img_path  = os.path.join(input_dir, fname)\n",
    "    save_path = os.path.join(output_dir, fname)\n",
    "\n",
    "    print(f\"生成中: {fname}...\")\n",
    "    Diffusion(img_path, save_path)\n",
    "\n",
    "print(\"完了しました！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16071000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch 2.8.0+cu129\n",
      "torchvision 0.23.0+cu129\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "\n",
    "print('torch', torch.__version__)\n",
    "print('torchvision', torchvision.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
